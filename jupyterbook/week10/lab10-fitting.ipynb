{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab10-fitting.ipynb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’»ðŸ§ª Lab 10: Combining Concepts to Build Interoperable Code for Plotting\n",
    "\n",
    "This lab uses all of the concepts we have learned in python programming to make reusable building blocks for generating, plotting, and fitting data. \n",
    "\n",
    "As an engineer you will regularly be presented with noisy data and want to fit that data to a function. In this assignment, we will build some machinery and a coding schema to generate noisy data (since we do not have real data), plot data, and fit the results. We will build tools to simplify the visualization of the results. The code will be designed to be interoperable. If we were to have a new type of data or mathematical expression, we could reuse all the code we have written. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entering Your Information for Credit\n",
    "\n",
    "To receive credit for assignments it is important we can identify your work from others. To do this we will ask you to enter your information in the following code block.\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "Run the block of code at the top of the notebook that imports and sets up the autograder. This will allow you to check your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "from subprocess import call\n",
    "import sys\n",
    "\n",
    "package_name = 'ENGR131_Util_2024'\n",
    "version = '1.0.0'\n",
    "package_version = f'{package_name}=={version}'\n",
    "\n",
    "try:\n",
    "    # Check if the package and version are installed\n",
    "    pkg_resources.require(package_version)\n",
    "    print(f'{package_version} is already installed.')\n",
    "except pkg_resources.DistributionNotFound:\n",
    "    # If not installed, install the package\n",
    "    print(f'{package_version} not found. Installing...')\n",
    "    call([sys.executable, '-m', 'pip', 'install', package_version])\n",
    "except pkg_resources.VersionConflict:\n",
    "    # If a different version is installed, you can choose to upgrade/downgrade\n",
    "    installed_packages = {dist.key: dist.version for dist in pkg_resources.working_set}\n",
    "    installed_version = installed_packages.get(package_name.lower())\n",
    "    print(f'{package_name} {installed_version} is installed, but {version} is required.')\n",
    "    # Optionally, upgrade or downgrade the package to the required version\n",
    "    call([sys.executable, '-m', 'pip', 'install', '--upgrade', package_version])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ENGR131_Util_2024 import responses, StudentInfoForm, cell_logger\n",
    "from ENGR131_Util_2024 import submit_question, ResponseStore, ValidateLogFile\n",
    "\n",
    "# Register the log function to be called before any cell is executed\n",
    "get_ipython().events.register('pre_run_cell', cell_logger)\n",
    "responses[\"assignment\"] = \"labs_10\"\n",
    "\n",
    "StudentInfoForm(**responses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. Importing Functions\n",
    "\n",
    "Here we will import some packages that we need for this assignment\n",
    "\n",
    "2.1 import `numpy` as `np`\n",
    "\n",
    "2.2 import the submodule `matplotlib.pyplot` and assign it to `plt`\n",
    "\n",
    "2.3 import from `scipy.optimize` the `curve_fit` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.1 you need to import numpy as np\n",
    "...\n",
    "\n",
    "# 2.2 You need to import the submodule matplotlib.pyplot and assign it to plt\n",
    "...\n",
    "\n",
    "# 2.3 You need to import from scipy.optimize the curve_fit function\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2-Importing Functions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3. Implementing a Class for MathExpressions\n",
    "\n",
    "In Python and programming in general, it is common to have a base class that adds functionality to an object. For example, if you have a car that you are building, you might want to add blind spot detection. You can create the blind spot detection software and hardware and install it on multiple cars types. We will do the same with a math function. We will build a class that adds a methods to fit and evaluate a math expression. \n",
    "\n",
    "When we build this class we need it to be flexible to accept math functions with a flexible number of input parameters. We implement a fit function where we can input any parameters into the function (this is important for optimization required to fit data), and an evaluate method which uses the parameters set during initialization. \n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "3.1 Define a `class` `MathExpression`.\n",
    "\n",
    "3.2 Build an initialization function. \n",
    "- The function should take a variable `func` which is a mathematical function\n",
    "- The function should accept `**kwargs` \n",
    "    - The `kwargs` will be the parameters of the fitting function \n",
    "    - We want to save the `kwargs`, each key-value pair of `kwargs` where the key is the variable name, and `func` as an attribute of the object\n",
    "\n",
    "3.3 Define a method `fit`.\n",
    "- That accepts a required input `x`, and `**kwargs`\n",
    "- Return the result when you call the objects method `func` that accepts a required input `x`, and `**kwargs`\n",
    "\n",
    "3.4 Define an method for the `class` `evaluate`.\n",
    "- Takes a required input `x`\n",
    "- Returns the result when you call the objects method `func` that accepts a required input `x`, and the `**kwargs` values set at initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.1 define a class MathExpression\n",
    "...\n",
    "    \n",
    "    # 3.2 Use the built in initialization function\n",
    "    # The function should take a variable func which is a mathematical function for generation and fitting (we will define this later)\n",
    "    # The function should accept **kwargs\n",
    "    # The kwargs will be the parameters of the fitting function \n",
    "    ...\n",
    "        \n",
    "        # use the .items() method to extract from kwargs a list of tuples with the key value pairs\n",
    "        # Create a for loop that extracts the key value pairs from the kwargs\n",
    "        #   make sure to unpack the tuple into the variables key and value\n",
    "        # Inside the for loop, use the built in python method setattr to add an attribute to the MathExpression Object \n",
    "        #   for the key, use the variable key, \n",
    "        #   for the value, use the variable value\n",
    "        ...\n",
    "        \n",
    "        # save the kwargs as an attribute of the object named kwargs\n",
    "        ...\n",
    "        \n",
    "        # save the function as an attribute of the object named func\n",
    "        ...\n",
    "        \n",
    "    # 3.3 for the class, define a method fit that accepts a required input x, and **kwargs\n",
    "    #   x is the points to sample along the x axis\n",
    "    #   **kwargs are new parameters to test\n",
    "    #   Note: this is a requirement of the fitting function\n",
    "    ...\n",
    "        \n",
    "        # return the result when you call the object's method func that accepts a required input x and **kwargs\n",
    "        ...\n",
    "        \n",
    "    # 3.4 for the class, define a method evaluate that takes a required input x\n",
    "    ...\n",
    "       \n",
    "        # return the result when you call the object's method func that accepts a required input x and the kwargs values set at initialization.\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3-Implement MathExpression\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4. Define a Linear Function\n",
    "\n",
    "$$ Y = slope * x + intercept $$\n",
    "\n",
    "We want to define a simple linear function. A linear model is one of the simplest fitting functions used in science and engineering. It says that an independent variable directly influences a dependent variable. \n",
    "\n",
    "4.1 Build a function `LinearFunction`\n",
    "- `LinearFunction` should take three inputs: `x` for the independent variable, `m` for the slope, `b` for the intercept.\n",
    "- Return the calculation of `y`, where y = slope * x + intercept. \n",
    "- Make sure to replace slope and intercept with the correct variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.1 build a function LinearFunction\n",
    "# linear function should take two inputs m - for the slope, and b for the intercept\n",
    "# return the calculation of y, where y = slope * x + intercept. \n",
    "# Make sure to replace slope and intercept with the correct variables.\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3 - Linear Function\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 5. Plotting\n",
    "\n",
    "One of the best ways to understand your code is doing what you expect is to visualize the results. We can do this by plotting the data. \n",
    "\n",
    "5.1 Instantiate an object `Linear_` using the `MathExpression` `Class`.\n",
    "- The input `func` should be the `LinearFunction` you wrote\n",
    "- The variables needed for kwargs must be provided as key value pairs. \n",
    "- In this case, those key value pairs are `m = 1`, and `b = -3`. \n",
    "\n",
    "5.2 Derive a linearly-spaced vector for the independent variable.\n",
    "- Use the `np.linspace` function to make a linearly-spaced array from `0` to `10` with `100` steps\n",
    "\n",
    "5.3. call the built-in `evaluate` method of the `LinearFunction` object over the range defined by `x`.\n",
    "- assign the output to a variable `y`\n",
    "\n",
    "5.4 Use the function `plt.plot` to plot `x` vs `y`.\n",
    "- assign the plot to a variable called `linear_plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5.1 Instantiate an object Linear_ using the MathExpression Class\n",
    "# The variables needed for the Kwargs m = 1, and b = -3 need to be provided as key value pairs. \n",
    "# example my_function(x=1), this would provide a **kwargs key (x) value (1)\n",
    "\n",
    "...\n",
    "\n",
    "# 5.2 use the np.linspace function to make a linearly-spaced array from 0 to 10, with 100 steps\n",
    "# save this to the variable x\n",
    "\n",
    "...\n",
    "\n",
    "# 5.3 call the built-in `evaluate` method of the LinearFunction object over the range defined by x\n",
    "# assign the output to a variable y\n",
    "\n",
    "...\n",
    "\n",
    "# 5.4 use the function plt.plot to plot x vs y\n",
    "\n",
    "...\n",
    "\n",
    "# we do not need to add more labels to this plot. It was just for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5 - Plotting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results are aaved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_question()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A NoisyFunction\n",
    "\n",
    "You are responsible for making a 3-4 minute VoiceThread submission that briefly explains each function of this class. *You are not responsible for writing any code or comments in this Task.*\n",
    "\n",
    "We have written a function with several useful methods that you might want to use as an engineer. \n",
    "\n",
    "6.1 It inherits information from an object of type `MathExpression`\n",
    "\n",
    "6.2 It can generate noisy data, which is to simulate real experimental data.\n",
    "\n",
    "6.3 It can fit the data to an known function. \n",
    "\n",
    "6.4 It can fit, plot and format the results for quick visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a class Noisy Function that Inherits MathExpression\n",
    "# This is simply done writing class NoisyFunction(MathExpression)\n",
    "class NoisyFunction(MathExpression):\n",
    "    \n",
    "    # This class does not require any specific initialization variables, but it will require that we pass the inherited variable through.\n",
    "    # we have done this for you \n",
    "    # you should not touch this code. If you do, here it is\n",
    "    # def __init__(self, *args, **kwargs):\n",
    "    #    super().__init__(*args, **kwargs)\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    # build a function generate noisy data with two required inputs\n",
    "    #   x_range - a list of the minimum and max ranges for to generate the data\n",
    "    #   noise_amplitude - a float from which sets the magnitude of the noise\n",
    "    def generate_noisy_data(self, x_range, noise_amplitude):\n",
    "        # use np.linspace to generate x data along the range\n",
    "        # generate 100 points\n",
    "\n",
    "        x = np.linspace(x_range[0], x_range[1], 100)\n",
    "        \n",
    "        # call the evaluate method of the base function object to return the true values\n",
    "\n",
    "        y_true = self.evaluate(x)\n",
    "        \n",
    "        # generate the noise vector by multiplying the noise amplitude by an random noise vector of length x  \n",
    "        # the random noise vector should be generated with np.random.randn\n",
    "\n",
    "        noise = noise_amplitude * np.random.randn(len(x))\n",
    "        \n",
    "        # add the noise to the y_true value\n",
    "        # save it in a new variable y\n",
    "\n",
    "        y = y_true + noise\n",
    "        \n",
    "        # return x, y, and y_true\n",
    "\n",
    "        return x, y, y_true\n",
    "\n",
    "    # build a function fit_data that takes 2 inputs x and y\n",
    "    def fit_data(self, x, y):\n",
    "        # call the curvefit function\n",
    "        # provide the inherited pointed to the function\n",
    "        # For the initial guess provide the true values they are contained within the saved variable kwargs\n",
    "        # You can get the values of a dictionary using the built-in method .values()\n",
    "        # P0 takes a list. You need to convert the values to a list.\n",
    "        # Curvefit should return two values assign them to popt and pcov. \n",
    "        # popt is the fit results\n",
    "\n",
    "        popt, pcov = curve_fit(self.func, x, y, p0=list(self.kwargs.values()))\n",
    "        \n",
    "        # Return popt and pcov\n",
    "\n",
    "        return popt, pcov\n",
    "\n",
    "    # build a function plot_fit_results that plots the raw and fit results\n",
    "    # This function should take two input parameters:\n",
    "    #   x_range - a tuple defining the x range to plot\n",
    "    #   noise_amplitude - a float used to control the magnitude of the noise\n",
    "    def plot_fit_results(self, x_range, noise_amplitude):\n",
    "    \n",
    "\n",
    "            # use the subplots function in pyplot to create a multiplot figure with 2 columns and 1 row.\n",
    "            # set the figure size = 10, 5 - figsize takes a tuple\n",
    "            # assign the output to two variables fig and axs\n",
    "    \n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            \n",
    "\n",
    "            # make a list of strings called labels \n",
    "            # The 0th index should be \"True Fit\"\n",
    "            # The 1st index should be \"Noisy Fit\"\n",
    "    \n",
    "            labels = ['True Fit', 'Noisy Fit']\n",
    "            \n",
    "\n",
    "            # call the generate_noisy_data function from this class\n",
    "            # save the returned variables to x, y, and y_true\n",
    "    \n",
    "            x, y, y_true = self.generate_noisy_data(x_range, noise_amplitude)\n",
    "            \n",
    "\n",
    "            # make a look that loops over the axs with enumerate.\n",
    "            # set the iterator equal to the variable i\n",
    "            # set the value equal to the variable ax\n",
    "    \n",
    "            for i, ax in enumerate(axs):\n",
    "                \n",
    "    \n",
    "                # create a scatterplot on the axis object \n",
    "                # plot x vs y\n",
    "                # make the marker size = 5 (with the `s` tag)\n",
    "                # add a label 'Raw Data' (with the `label` tag)\n",
    "        \n",
    "                ax.scatter(x, y, s=5, label='Raw Data')\n",
    "                \n",
    "    \n",
    "                # write an if statement that is true if the label of the graph is \"True Fit\". This is ordered by the list labels you created.\n",
    "        \n",
    "                if labels[i] == 'True Fit':\n",
    "                    \n",
    "        \n",
    "                    # if the statement was true on the axis object plot\n",
    "                    # x vs y true\n",
    "                    # make the line red using the 'r' flag\n",
    "                    # add a label as indexed from the list\n",
    "            \n",
    "                    ax.plot(x, y_true, 'r', label=labels[i])\n",
    "                \n",
    "    \n",
    "                # add an elif statement that is true if the label of the graph is \"Noisy Fit\" this is ordered by the list labels you created.\n",
    "        \n",
    "                elif labels[i] == 'Noisy Fit':\n",
    "                    \n",
    "        \n",
    "                    # call the method in the class fit_data\n",
    "                    # This should fit the x and y data\n",
    "                    # have it return the variables popt and pcov\n",
    "            \n",
    "                    popt, pcov = self.fit_data(x, y)\n",
    "                    \n",
    "        \n",
    "                    # use the predicted popt and the inherited function to generate the y values for the fit results\n",
    "                    # make sure to unpack the popt list with the * operator\n",
    "            \n",
    "                    y_noisy_fit = self.func(x, *popt)\n",
    "                    \n",
    "        \n",
    "                    # on the axis object plot\n",
    "                    # x vs y_noisy_fit\n",
    "                    # make the line blue using the 'b' flag\n",
    "                    # add a label as indexed from the list\n",
    "            \n",
    "                    ax.plot(x, y_noisy_fit, 'b', label=labels[i])\n",
    "                 \n",
    "    \n",
    "                # else passes to the next loop\n",
    "            \n",
    "                else: \n",
    "                    pass\n",
    "            \n",
    "    \n",
    "                # use the set_xlabel method to set the x-label of the graph to 'x'\n",
    "                # use the set_ylabel method to set the y-label of the graph to 'y'\n",
    "        \n",
    "                ax.set_xlabel('x')\n",
    "                ax.set_ylabel('y')\n",
    "                \n",
    "    \n",
    "                # call the legend method of the axis object to show the legend\n",
    "        \n",
    "                ax.legend()\n",
    "                               \n",
    "            return fig\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 7. Testing our Class\n",
    "\n",
    "In coding it is always a good idea to run all parts of your code to check it is performing as expected. \n",
    "\n",
    "7.1 Create a `NoisyFunction` instance for a linear function\n",
    "- Assign this object to the variable `linear_func`\n",
    "- The input `func` should be the `LinearFunction` you wrote\n",
    "- The slope should be `3` and the intercept should be `4`\n",
    "\n",
    "7.2 Call the proper method of `linear_func` to generate noisy data over the range from 0- $2\\pi$\n",
    "- the noise amplitude is `1`\n",
    "- save the results to `x`, `y`, and `y_true`\n",
    "\n",
    "7.3 Fit the `x` and `y` data using the proper method of `linear_func`\n",
    "- save the fit results to `popt`, `pcov`\n",
    "- (these names represent the optimal parameters (`popt`) and the parameters' covariance (`pcov`))\n",
    "\n",
    "7.4 Use the built-in method to plot the fit result\n",
    "- set the range equal to `0` to `16`\n",
    "- set the noise amplitude equal to `0.3`\n",
    "- Save this to the variable plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(42)\n",
    "\n",
    "# 7.1 Create a NoisyFunction instance for a linear function\n",
    "# Assign this object to the variable linear_func\n",
    "# The slope should be 3 and the intercept should be 4\n",
    "linear_func = ...\n",
    "\n",
    "# 7.2 call the generate_noisy_data function of the object the linear_func to produce noisy data over the range from 0-2pi\n",
    "#   use a tuple to indicate the range from 0-2pi\n",
    "#   the noise amplitude is 1\n",
    "#   save the results to x, y, and y_true\n",
    "x, y, y_true  = ...\n",
    "\n",
    "# 7.3 Fit the data\n",
    "# save the fit results to popt, pcov\n",
    "popt, pcov = ...\n",
    "\n",
    "# 7.4 Use the built-in method to plot the fit result\n",
    "# set the range equal to 0 to 16\n",
    "# set the noise amplitude equal to 0.3\n",
    "# Save this to the variable plot\n",
    "plot = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7 - plotting and fitting\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 8. Defining new math functions\n",
    "\n",
    "Now we can view the flexibility (interoperability) of our code. \n",
    "\n",
    "Define two new functions. Follow the logic of the way you created `LinearFunction`.\n",
    "\n",
    "8.1 `SineFunction`\n",
    "   \n",
    "$$g(x) = A (sin(2\\pi f x+\\phi))$$\n",
    "\n",
    "where $A$ represents amplitude, $f$ represents the frequency, and $\\phi$ represents the phase.\n",
    "\n",
    "8.2 `ExponentialFunction`\n",
    "\n",
    "$$h(x) = ae^{bx}$$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8.1 Write the SineFunction here\n",
    "# the inputs should be x, amplitude, frequency, phase\n",
    "...\n",
    "\n",
    "# 8.1 Write the ExponentialFunction here\n",
    "# the inputs should be x, a, b\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8-new functions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 9 Using our class with the sine function\n",
    "\n",
    "Now we can use nearly the same code from Task 7 to test our `SineFunction`.\n",
    "\n",
    "9.1 Create a `NoisyFunction` instance for the sine function\n",
    "- Assign this object to the variable `sine_func`\n",
    "- The input `func` should be the `SineFunction` you wrote\n",
    "- The amplitude should be 2, the frequency should be .2, and the phase should be .5\n",
    "\n",
    "9.2 Apply the `generate_noisy_data` method of `sine_func` to produce noisy data over the range from 0-6 $\\pi$\n",
    "- use a tuple to indicate the range from 0-6 $\\pi$\n",
    "- the noise amplitude is 1.5\n",
    "- save the results to `x`, `y`, and `y_true`\n",
    "\n",
    "9.3 Fit the `x` and `y` data using the proper method of `sine_func`\n",
    "- save the fit results to `popt`, `pcov`\n",
    "\n",
    "9.4 Use the built-in method to plot the fit results\n",
    "- set the range equal to 0 to 6 $\\pi$\n",
    "- set the noise amplitude equal to 1.5\n",
    "- Save this to the variable `plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(42)\n",
    "\n",
    "# 9.1 Create a NoisyFunction instance for a sine function\n",
    "# Assign this object to the variable sine_func\n",
    "# The amplitude should be 2, the frequency should be .2, and the phase should be .5\n",
    "sine_func = ...\n",
    "\n",
    "# 9.2 evaluate the sine_func to produce noisy data over the range from 0-6pi\n",
    "# the noise amplitude is 1.5\n",
    "# save the results to x, y, and y_true\n",
    "x, y, y_true  = ...\n",
    "\n",
    "# 9.3 Fit the data\n",
    "# save the fit results to popt, pcov\n",
    "popt, pcov = ...\n",
    "\n",
    "# 9.4 Use the built-in method to plot the fit results\n",
    "# set the range equal to 0 to 6 pi\n",
    "# set the noise amplitude equal to 1.5\n",
    "# Save this to the variable plot\n",
    "plot = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9-using the class with new Sine functions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# 10 Using our class with the Exponential function\n",
    "\n",
    "Now we can use nearly the exact same code to test our Exponential function. We wrote one code that we can use over and over again in different ways!\n",
    "\n",
    "10.1 Create a `NoisyFunction` instance for a exponential function\n",
    "- Assign this object to the variable `exp_func`\n",
    "- The input `func` should be the `ExponentialFunction` you wrote\n",
    "- `a` should be 2, and `b` should be .2\n",
    "\n",
    "10.2 Call the proper method of `exp_func` to generate noisy data over the range from 0-6 $\\pi$\n",
    "- use a tuple to indicate the range from 0-6 $\\pi$\n",
    "- the noise amplitude is 1.5\n",
    "- save the results to `x`, `y`, and `y_true`\n",
    "\n",
    "10.3 Fit the `x` and `y` data using the proper method of `exp_func`\n",
    "- save the fit results to `popt`, `pcov`\n",
    "\n",
    "10.4 Use the built-in method to plot the fit results\n",
    "- set the range equal to 0 to 6 $\\pi$\n",
    "- set the noise amplitude equal to 1.5\n",
    "- save this to the variable `plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(42)\n",
    "\n",
    "# 10.1 Create a NoisyFunction instance for a exponential function\n",
    "# Assign this object to the variable exp_func\n",
    "# The a should be 2, and b should be .2\n",
    "exp_func = ...\n",
    "\n",
    "# 10.2 evaluate the exp_func to produce noisy data over the range from 0-6pi\n",
    "# the noise amplitude is 1.5\n",
    "# save the results to x, y, and y_true\n",
    "x, y, y_true  = ...\n",
    "\n",
    "# 10.3 Fit the data\n",
    "# save the fit results to popt, pcov\n",
    "popt, pcov = ...\n",
    "\n",
    "# 10.4 Use the built-in method to plot the fit results\n",
    "# set the range equal to 0 to 6 pi\n",
    "# set the noise amplitude equal to 1.5\n",
    "# Save this to the variable plot\n",
    "plot = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10-using the class with new exponential functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended\n",
    "\n",
    "We recommend that you run the following code to ensure your responses are recorded. This is an extra measure to ensure your results are aaved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_question()\n",
    "ValidateLogFile(\"./output.log\", responses[\"assignment\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Your Assignment\n",
    "\n",
    "To submit your assignment please use the following link the assignment on GitHub classroom.\n",
    "   \n",
    "Use this [link](https://classroom.github.com/a/xlac6lYB) to navigate to the assignment on GitHub classroom.\n",
    "\n",
    "If you need further instructions on submitting your assignment please look at Lab 1. \n",
    "\n",
    "## Viewing your score\n",
    "\n",
    "**It is your responsibility to ensure that your grade report shows correctly. We can only provide corrections to grades if a grading error is determined. If you do not receive a grade report your grade has not been recorded. It is your responsibility either resubmit the assignment correctly or contact the instructors before the assignment due date.**\n",
    "\n",
    "Each `.ipynb` file you have uploaded will have a file with the name of your file + `Grade_Report.md`. You can view this file by clicking on the file name. This will show you the results of the autograder. \n",
    "\n",
    "We have both public and hidden tests. You will be able to see the score of both tests, but not the specific details of why the test passed or failed. \n",
    "\n",
    "```{note}\n",
    "In python and particularly jupyter notebooks it is common that during testing you run cells in a different order, or run cells and modify them. This can cause there to be local variables needed for your solution that would not be recreated on running your code again from scratch. Your assignment will be graded based on running your code from scratch. This means before you submit your assignment you should restart the kernel and run all cells. You can do this by clicking `Kernel` and selecting `Restart and Run All`. If you code does not run as expected after restarting the kernel and running all cells it means you have an error in your code. \n",
    "```\n",
    "\n",
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q10-using the class with new exponential functions": {
     "name": "q10-using the class with new exponential functions",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> points_ = [1, 0, 1, 4, 5]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_1'\n>>> max_score = 1\n>>> score = 0\n>>> if isinstance(exp_func, NoisyFunction) and exp_func.a == 2 and (exp_func.b == 0.2) and (exp_func.func == ExponentialFunction):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isinstance(exp_func, NoisyFunction)\n>>> assert exp_func.a == 2\n>>> assert exp_func.b == 0.2\n>>> assert exp_func.func == ExponentialFunction\n",
         "failure_message": "exp_func implemented incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "exp_func implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_2'\n>>> max_score = 0\n>>> score = 0\n>>> if seed == np.random.seed(42):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert seed == np.random.seed(42)\n",
         "failure_message": "You might have deleted the line that sets the random seed. Please add it at the top of the cell. You will fail the autograder if you do not place the seed in the top of the cell.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Your seed is still correct"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_3'\n>>> max_score = 1\n>>> score = 0\n>>> if np.isclose(sum([x, y, y_true])[4], 5.068497807066033, rtol=0.01) and np.isclose(np.mean(sum([x, y, y_true])[4::3]), 54.848917146243046, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(sum([x, y, y_true])[4], 5.068497807066033, rtol=0.01)\n>>> assert np.isclose(np.mean(sum([x, y, y_true])[4::3]), 54.848917146243046, rtol=0.01)\n",
         "failure_message": "x, y, y_true return incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "x, y, y_true return correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_4'\n>>> max_score = 4\n>>> score = 0\n>>> if np.isclose(popt[0], 1.9635667563774726, rtol=0.01) and np.isclose(popt[1], 0.20098217114795966, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(popt[0], 1.9635667563774726, rtol=0.01)\n>>> assert np.isclose(popt[1], 0.20098217114795966, rtol=0.01)\n",
         "failure_message": "Fitting function incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "Fitting function correctly implemented"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q8_5'\n>>> max_score = 5\n>>> score = 0\n>>> if np.isclose(np.sum(plot.axes[0].get_lines()[0].get_xydata()), 3212.76954915798, rtol=0.01) and np.isclose(np.sum(plot.axes[1].get_lines()[0].get_xydata()), 3220.812931722522, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(np.sum(plot.axes[0].get_lines()[0].get_xydata()), 3212.76954915798, rtol=0.01)\n>>> assert np.isclose(np.sum(plot.axes[1].get_lines()[0].get_xydata()), 3220.812931722522, rtol=0.01)\n",
         "failure_message": "plot incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 5,
         "success_message": "plot implemented correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2-Importing Functions": {
     "name": "q2-Importing Functions",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> points_ = [1, 1, 1]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q1_1'\n>>> max_score = 1\n>>> score = 0\n>>> if np.__version__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.__version__ is not None\n",
         "failure_message": "numpy random incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "numpy correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q1_2'\n>>> max_score = 1\n>>> score = 0\n>>> if plt.__package__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert plt.__package__ is not None\n",
         "failure_message": "plt random incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "plt correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q1_3'\n>>> max_score = 1\n>>> score = 0\n>>> if curve_fit.__name__ is not None:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert curve_fit.__name__ is not None\n",
         "failure_message": "plt random incorrectly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "plt correctly implemented."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3 - Linear Function": {
     "name": "q3 - Linear Function",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> from inspect import isfunction\n>>> points_ = [1, 1, 1]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q3_1'\n>>> max_score = 1\n>>> score = 0\n>>> if isfunction(LinearFunction):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isfunction(LinearFunction)\n",
         "failure_message": "LinearFunction is not a function",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "LinearFunction is a function"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import inspect\n>>> signature = inspect.signature(LinearFunction)\n>>> num_parameters = len(signature.parameters)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q3_2'\n>>> max_score = 1\n>>> score = 0\n>>> if num_parameters == 2:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert num_parameters == 3\n",
         "failure_message": "LinearFunction function has the incorrect inputs.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "LinearFunction function has the correct inputs."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> x = np.array([2, 3, 4, 5, 8, 10])\n>>> out = LinearFunction(x, 7, 4)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q3_3'\n>>> max_score = 1\n>>> score = 0\n>>> if all(out == [18, 25, 32, 39, 60, 74]):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert all(out == [18, 25, 32, 39, 60, 74])\n",
         "failure_message": "LinearFunction function implemented incorrect inputs.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "LinearFunction function implemented correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3-Implement MathExpression": {
     "name": "q3-Implement MathExpression",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> points_ = [1, 1, 2, 1, 1, 3, 1, 3]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_1'\n>>> max_score = 1\n>>> score = 0\n>>> if isinstance(MathExpression, type):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isinstance(MathExpression, type)\n",
         "failure_message": "MathExpression is not a Class",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "MathExpression is a Class"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_2'\n>>> max_score = 1\n>>> score = 0\n>>> if '__init__' in dir(MathExpression):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert '__init__' in dir(MathExpression)\n",
         "failure_message": "__init__ not implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "__init__ implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> out = MathExpression('a', b=1, test='test')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_3'\n>>> max_score = 2\n>>> score = 0\n>>> if out.kwargs['b'] == 1 and out.kwargs['test'] == 'test':\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert out.kwargs['b'] == 1\n>>> assert out.kwargs['test'] == 'test'\n",
         "failure_message": "MathExpression inputs kwargs not correctly implemented.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "MathExpression inputs kwargs correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> out = MathExpression(np.sum)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_4'\n>>> max_score = 1\n>>> score = 0\n>>> if out.func is np.sum:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert out.func is np.sum\n",
         "failure_message": "MathExpression function input not correctly implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "MathExpression function input correctly implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_5'\n>>> max_score = 1\n>>> score = 0\n>>> if 'fit' in dir(MathExpression):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert 'fit' in dir(MathExpression)\n",
         "failure_message": "fit is not implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "fit is implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> \n>>> def test(x, **kwargs):\n...     return (x, kwargs)\n>>> out = MathExpression(test)\n>>> (a, b) = out.fit(2, a=2, b=3)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_6'\n>>> max_score = 3\n>>> score = 0\n>>> if a == 2 and b == {'a': 2, 'b': 3}:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert a == 2\n>>> assert b == {'a': 2, 'b': 3}\n",
         "failure_message": "fit is not implemented correctly.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "fit is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_7'\n>>> max_score = 1\n>>> score = 0\n>>> if 'evaluate' in dir(MathExpression):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert 'evaluate' in dir(MathExpression)\n",
         "failure_message": "evaluate is not implemented.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "evaluate is implemented."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> \n>>> def test(x, **kwargs):\n...     return (x, kwargs)\n>>> out = MathExpression(test, a=5, b=3)\n>>> (a, b) = out.evaluate(2)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q2_8'\n>>> max_score = 3\n>>> score = 0\n>>> if a == 2 and b == {'a': 5, 'b': 3}:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert a == 2\n>>> assert b == {'a': 5, 'b': 3}\n",
         "failure_message": "evaluate is not implemented correctly.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "evaluate is implemented correctly."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5 - Plotting": {
     "name": "q5 - Plotting",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> points_ = [1, 1, 1, 3]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q4_1'\n>>> max_score = 2\n>>> score = 0\n>>> if '__init__' in dir(MathExpression):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isinstance(Linear_, MathExpression)\n>>> assert Linear_.m == 1\n>>> assert Linear_.b == -3\n",
         "failure_message": "MathExpression is not instantiated correctly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "MathExpression is instantiated correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q4_2'\n>>> max_score = 1\n>>> score = 0\n>>> if np.isclose(x[0], 0) and np.isclose(x[-1], 10) and (x.__len__() == 100):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(sum(x[::4]), 121.212121, rtol=0.01)\n>>> assert x.__len__() == 100\n",
         "failure_message": "X vector is incorrect",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "X vector is correct"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q4_3'\n>>> max_score = 1\n>>> score = 0\n>>> if sum(y) == 200:\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert sum(y) == 200\n",
         "failure_message": "evaluate computed incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "evaluate computed correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q4_4'\n>>> max_score = 3\n>>> score = 0\n>>> if 700 == np.sum(linear_plot[0].get_data()):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert 700 == np.sum(linear_plot[0].get_data())\n",
         "failure_message": "The plot is incorrect",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "The plot is correct"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7 - plotting and fitting": {
     "name": "q7 - plotting and fitting",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> points_ = [1, 0, 1, 4]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_1'\n>>> max_score = 1\n>>> score = 0\n>>> if isinstance(linear_func, NoisyFunction) and linear_func.m == 3 and (linear_func.b == 4) and (linear_func.func == LinearFunction):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isinstance(linear_func, NoisyFunction)\n>>> assert linear_func.m == 3\n>>> assert linear_func.b == 4\n>>> assert linear_func.func == LinearFunction\n",
         "failure_message": "linear_func implemented incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "linear_func implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_2'\n>>> max_score = 0\n>>> score = 0\n>>> if seed == np.random.seed(42):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert seed == np.random.seed(42)\n",
         "failure_message": "You might have deleted the line that sets the random seed. Please add it at the top of the cell. You will fail the autograder if you do not place the seed in the top of the cell.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Your seed is still correct"
        },
        {
         "code": ">>> seed = np.random.seed(42)\n>>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_3'\n>>> max_score = 1\n>>> score = 0\n>>> if np.isclose(sum([x, y, y_true])[4], 9.542909136398162, rtol=0.01) and np.isclose(np.mean(sum([x, y, y_true])[4::3]), 30.365526866857397, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(sum([x, y, y_true])[4], 9.542909136398162, rtol=0.01)\n>>> assert np.isclose(np.mean(sum([x, y, y_true])[4::3]), 30.365526866857397, rtol=0.01)\n",
         "failure_message": "x, y, y_true return incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "x, y, y_true return correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_4'\n>>> max_score = 4\n>>> score = 0\n>>> if np.isclose(popt[0], 3.0219526649250503, rtol=0.01) and np.isclose(popt[1], 3.8271871517503655, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(popt[0], 3.0219526649250503, rtol=0.01)\n>>> assert np.isclose(popt[1], 3.8271871517503655, rtol=0.01)\n",
         "failure_message": "Fitting function incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "Fitting function correctly implemented"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q5_5'\n>>> max_score = 2\n>>> score = 0\n>>> if '__init__' in dir(MathExpression):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.sum(plot.axes[0].get_lines()[0].get_xydata()) == 3600\n>>> assert np.isclose(np.sum(plot.axes[1].get_lines()[0].get_xydata()), 3600.6691376113495, rtol=0.01)\n",
         "failure_message": "plot incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 5,
         "success_message": "plot implemented correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8-new functions": {
     "name": "q8-new functions",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import inspect\n>>> signature = inspect.signature(SineFunction)\n>>> num_parameters = len(signature.parameters)\n>>> seed = np.random.seed(42)\n>>> points_ = [3, 3]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_1'\n>>> max_score = 3\n>>> score = 0\n>>> if num_parameters == 4 and np.allclose([-1.51360499, -0.77557439, -0.456128], SineFunction(np.array([0.0, 0.1, 0.3]), 2, 3, 4), rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert num_parameters == 4\n>>> assert np.allclose([-1.51360499, -0.77557439, -0.456128], SineFunction(np.array([0.0, 0.1, 0.3]), 2, 3, 4), rtol=0.01)\n",
         "failure_message": "SineFunction incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "SineFunction implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> import inspect\n>>> signature = inspect.signature(ExponentialFunction)\n>>> num_parameters = len(signature.parameters)\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q6_2'\n>>> max_score = 3\n>>> score = 0\n>>> if num_parameters == 3 and np.allclose([2.0, 2.69971762, 4.91920622], ExponentialFunction(np.array([0.0, 0.1, 0.3]), 2, 3), rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert num_parameters == 3\n>>> assert np.allclose([2.0, 2.69971762, 4.91920622], ExponentialFunction(np.array([0.0, 0.1, 0.3]), 2, 3), rtol=0.01)\n",
         "failure_message": "SineFunction incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "SineFunction implemented correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9-using the class with new Sine functions": {
     "name": "q9-using the class with new Sine functions",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> points_ = [1, 0, 1, 4, 5]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_1'\n>>> max_score = 1\n>>> score = 0\n>>> if isinstance(sine_func, NoisyFunction) and sine_func.amplitude == 2 and (sine_func.frequency == 0.2) and (sine_func.phase == 0.5) and (sine_func.func == SineFunction):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert isinstance(sine_func, NoisyFunction)\n>>> assert sine_func.amplitude == 2\n>>> assert sine_func.frequency == 0.2\n>>> assert sine_func.phase == 0.5\n>>> assert sine_func.func == SineFunction\n",
         "failure_message": "sine_func implemented incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "sine_func implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_2'\n>>> max_score = 0\n>>> score = 0\n>>> if seed == np.random.seed(42):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert seed == np.random.seed(42)\n",
         "failure_message": "You might have deleted the line that sets the random seed. Please add it at the top of the cell. You will fail the autograder if you do not place the seed in the top of the cell.",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Your seed is still correct"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_3'\n>>> max_score = 1\n>>> score = 0\n>>> if np.isclose(sum([x, y, y_true])[4], 4.384520747622161, rtol=0.01) and np.isclose(np.mean(sum([x, y, y_true])[4::3]), 9.50518884876772, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(sum([x, y, y_true])[4], 4.384520747622161, rtol=0.01)\n>>> assert np.isclose(np.mean(sum([x, y, y_true])[4::3]), 9.50518884876772, rtol=0.01)\n",
         "failure_message": "x, y, y_true return incorrectly",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "x, y, y_true return correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_4'\n>>> max_score = 4\n>>> score = 0\n>>> if np.isclose(popt[0], 2.2550781375831015, rtol=0.01) and np.isclose(popt[1], 0.19762745754501546, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(popt[0], 2.2550781375831015, rtol=0.01)\n>>> assert np.isclose(popt[1], 0.19762745754501546, rtol=0.01)\n",
         "failure_message": "Fitting function incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "Fitting function correctly implemented"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> import json\n>>> from ENGR131_Util_2024 import responses, ResponseStore\n>>> seed = np.random.seed(42)\n>>> responder = ResponseStore()\n>>> responder.create_file()\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> question_id = 'q7_5'\n>>> max_score = 5\n>>> score = 0\n>>> if np.isclose(np.sum(plot.axes[0].get_lines()[0].get_xydata()), 944.5788167212941, rtol=0.01) and np.isclose(np.sum(plot.axes[1].get_lines()[0].get_xydata()), 943.8768017567118, rtol=0.01):\n...     score = max_score\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': ''}\n>>> responder.add_response(response)\n>>> assert np.isclose(np.sum(plot.axes[0].get_lines()[0].get_xydata()), 944.5788167212941, rtol=0.01)\n>>> assert np.isclose(np.sum(plot.axes[1].get_lines()[0].get_xydata()), 943.8768017567118, rtol=0.01)\n",
         "failure_message": "plot incorrectly implemented",
         "hidden": false,
         "locked": false,
         "points": 5,
         "success_message": "plot implemented correctly"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "db982e328663a2db3b6f47ccd278f30154ccd8de8e195897b14b89b93466dc3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
