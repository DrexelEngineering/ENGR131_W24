{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"quiz9-classes-practice.ipynb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# ⌛️ Quiz 9 Practice - Classes\n",
    "\n",
    "This quiz will evaluate your mastery of using classes in Python. Functions provide a way to isolate code that you want to use repeatedly, and they allow you to pass in data to the code and get data back out of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Entering Your Information for Credit\n",
    "\n",
    "To receive credit for assignments it is important we can identify your work from others. To do this we will ask you to enter your information in the following code block.\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "Run the block of code at the top of the notebook that imports and sets up the autograder. This will allow you to check your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "from subprocess import call\n",
    "import sys\n",
    "\n",
    "package_name = 'ENGR131_Util_2024'\n",
    "version = '0.1.11'\n",
    "package_version = f'{package_name}=={version}'\n",
    "\n",
    "try:\n",
    "    # Check if the package and version are installed\n",
    "    pkg_resources.require(package_version)\n",
    "    print(f'{package_version} is already installed.')\n",
    "except pkg_resources.DistributionNotFound:\n",
    "    # If not installed, install the package\n",
    "    print(f'{package_version} not found. Installing...')\n",
    "    call([sys.executable, '-m', 'pip', 'install', package_version])\n",
    "except pkg_resources.VersionConflict:\n",
    "    # If a different version is installed, you can choose to upgrade/downgrade\n",
    "    installed_packages = {dist.key: dist.version for dist in pkg_resources.working_set}\n",
    "    installed_version = installed_packages.get(package_name.lower())\n",
    "    print(f'{package_name} {installed_version} is installed, but {version} is required.')\n",
    "    # Optionally, upgrade or downgrade the package to the required version\n",
    "    call([sys.executable, '-m', 'pip', 'install', '--upgrade', package_version])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "from ENGR131_Util_2024 import cell_logger, StudentInfoForm, responses, upsert_to_json_file\n",
    "# Register the log function to be called before any cell is executed\n",
    "get_ipython().events.register('pre_run_cell', cell_logger)\n",
    "responses[\"assignment\"] = \"quiz_9_practice\"\n",
    "\n",
    "StudentInfoForm(**responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question: Machine Learning Model Resource Estimator\n",
    "\n",
    "### Background\n",
    "\n",
    "In the field of machine learning and artificial intelligence, estimating the computational resources required for training a model is critical for efficiency and cost management. The total resource requirement includes both the static load (the base computational power and memory needed for the model architecture, datasets, and fixed algorithms) and the dynamic load (additional resources required for training iterations, data augmentation, and validation processes).\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Implement a `ModelResourceEstimator` class to model the resource requirements for training a machine learning model.\n",
    "2. Include methods within this class to calculate the static load, dynamic load, and total resource requirement.\n",
    "3. Demonstrate the use of class initialization, basic math calculations, and functions calling other functions.\n",
    "\n",
    "### Class to Implement\n",
    "\n",
    "Implement a class `ModelResourceEstimator` with the following properties and methods:\n",
    "   - Methods:\n",
    "     - `__init__`: Initializes a new `ModelResourceEstimator` instance with the properties.\n",
    "         - Properties:\n",
    "           - `model_complexity` (a measure of model complexity, e.g., the number of parameters)\n",
    "           - `data_size` (in gigabytes, GB, representing the size of the dataset used for training)\n",
    "           - `iterations` (the number of training iterations)\n",
    "           - `base_resource_per_iteration` (in gigaflops per iteration, representing the base computational resource usage per training iteration)\n",
    "           - `memory_usage_static` (in gigabytes, GB, representing the static memory usage by the model and dataset)\n",
    "     - `static_load`: Calculates and returns the static resource load for training the model.\n",
    "       - The static load includes the base static memory usage.\n",
    "     - `dynamic_load`: Calculates and returns the dynamic resource load for the model based on the number of iterations and base resource per iteration.\n",
    "       - The dynamic load is calculated as the product of the number of iterations and the base resource usage per iteration.\n",
    "     - `total_resource_requirement`: Calculates and returns the total resource requirement by summing its static and dynamic loads.\n",
    "       - The total resource requirement is the sum of the static and dynamic loads.\n",
    "     - `print_resource_requirements`: Prints the static, dynamic, and total resource requirements in the following format:\n",
    "       - \"Static Load: \"{static_load} GB\\nDynamic Load: {dynamic_load} GFLOPs\\nTotal Resource Requirement: {total_resource_requirement} (GB for static load and GFLOPs for dynamic load)\" where the values are extracted from the object rounded to 2 decimal places.\n",
    "       - Note: you must use a **single print command**, \\n is used to create a new line in the print statement.\n",
    "\n",
    "Instantiate a `ModelResourceEstimator` object with the following properties:\n",
    "\n",
    "   - Model complexity: High (not directly quantified here, but influences resource estimation)\n",
    "   - Dataset size: 10 GB\n",
    "   - Number of training iterations: 1000\n",
    "   - Base computational resource per iteration: 5 gigaflops\n",
    "   - Static memory usage: 2 GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Your Class for a Machine Learning Model Resource Estimator goes Here\n",
    "...\n",
    "\n",
    "# Instantiate a ModelResourceEstimator object with the specified properties\n",
    "...\n",
    "\n",
    "# Print the static, dynamic, and total resource requirements\n",
    "# you can uncomment this line for testing\n",
    "# model_resource_estimator.print_resource_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1-ML-Resource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "\n",
    "## Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1-ML-Resource": {
     "name": "q1-ML-Resource",
     "points": 42,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> points_ = [6, 4, 5, 4, 4, 4, 4, 6, 5]\n>>> for (i, point) in enumerate(points_):\n...     drexel_jupyter_logger.variable_logger_csv(f'0, {point}', f'q1_{i + 1}')\n>>> import json\n>>> student_data = {'first_name': responses['first_name'], 'last_name': responses['last_name'], 'drexel_id': responses['drexel_id'], 'drexel_email': responses['drexel_email']}\n>>> with open('student_data.json', 'w') as json_file:\n...     json.dump(student_data, json_file)\n>>> scorer = submit_score()\n>>> question_id = 'q1_1'\n>>> max_score = 6\n>>> score = 0\n>>> for method in ['__init__', 'model_complexity', 'data_size', 'iterations', 'base_resource_per_iteration', 'memory_usage_static']:\n...     if hasattr(model_resource_estimator, method):\n...         score += 1\n>>> score = int(np.ceil(score))\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': dir(model_resource_estimator)}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert hasattr(model_resource_estimator, '__init__'), '__init__ method is not implemented'\n>>> assert hasattr(model_resource_estimator, 'model_complexity'), 'model_complexity method is not implemented'\n>>> assert hasattr(model_resource_estimator, 'data_size'), 'data_size method is not implemented'\n>>> assert hasattr(model_resource_estimator, 'iterations'), 'iterations method is not implemented'\n>>> assert hasattr(model_resource_estimator, 'base_resource_per_iteration'), 'base_resource_per_iteration method is not implemented'\n>>> assert hasattr(model_resource_estimator, 'memory_usage_static'), 'memory_usage_static method is not implemented'\n",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "All methods are implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> if 'drexel_email' not in responses:\n...     raise ValueError('Please fill out the student info form and run the test again')\n>>> scorer = submit_score()\n>>> question_id = 'q1_2'\n>>> max_score = 2\n>>> score = 0\n>>> if len(ModelResourceEstimator.__init__.__code__.co_varnames) == 6:\n...     score += 2\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': dir(model_resource_estimator)}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert len(ModelResourceEstimator.__init__.__code__.co_varnames) == 6, '__init__ method does not take the correct number of parameters'\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "Init takes the correct number of parameters"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> import numpy as np\n>>> scorer = submit_score()\n>>> question_id = 'q1_3'\n>>> max_score = 5\n>>> score = 0\n>>> for method in ['model_complexity', 'data_size', 'iterations', 'base_resource_per_iteration', 'memory_usage_static']:\n...     if hasattr(model_resource_estimator, method):\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': dir(model_resource_estimator)}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert hasattr(model_resource_estimator, 'model_complexity'), 'model_complexity attribute is not implemented'\n>>> assert hasattr(model_resource_estimator, 'data_size'), 'data_size attribute is not implemented'\n>>> assert hasattr(model_resource_estimator, 'iterations'), 'iterations attribute is not implemented'\n>>> assert hasattr(model_resource_estimator, 'base_resource_per_iteration'), 'base_resource_per_iteration attribute is not implemented'\n>>> assert hasattr(model_resource_estimator, 'memory_usage_static'), 'memory_usage_static attribute is not implemented'\n",
         "hidden": false,
         "locked": false,
         "points": 5,
         "success_message": "All properties are implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> scorer = submit_score()\n>>> question_id = 'q1_4'\n>>> max_score = 4\n>>> score = 0\n>>> m1 = ModelResourceEstimator(model_complexity='High', data_size=10, iterations=1000, base_resource_per_iteration=5, memory_usage_static=2)\n>>> test = m1.static_load() == 2\n>>> statement = 'static_load method is not implemented correctly'\n>>> value = m1.static_load()\n>>> if test:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': value}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert test, statement\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "static_load method is implemented correctly."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> scorer = submit_score()\n>>> question_id = 'q1_5'\n>>> max_score = 4\n>>> score = 0\n>>> m1 = ModelResourceEstimator(model_complexity='High', data_size=10, iterations=1000, base_resource_per_iteration=5, memory_usage_static=2)\n>>> value = m1.static_load()\n>>> test = m1.static_load() == 2\n>>> statement = 'static load method is not implemented correctly'\n>>> if test:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': value}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert test, statement\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "static load implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> scorer = submit_score()\n>>> question_id = 'q1_6'\n>>> max_score = 4\n>>> score = 0\n>>> estimator = ModelResourceEstimator(model_complexity='High', data_size=10, iterations=1000, base_resource_per_iteration=5, memory_usage_static=2)\n>>> value = estimator.dynamic_load()\n>>> test = value == 5000\n>>> statement = 'dynamic load method is not implemented correctly'\n>>> if test:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': value}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert test, statement\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "dynamic load implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from ENGR131_Util_2024 import submit_score\n>>> from unittest.mock import patch\n>>> scorer = submit_score()\n>>> question_id = 'q1_7'\n>>> max_score = 4\n>>> score = 0\n>>> mre = ModelResourceEstimator(model_complexity='High', data_size=10, iterations=1000, base_resource_per_iteration=5, memory_usage_static=2)\n>>> value = mre.total_resource_requirement()\n>>> test = value == mre.static_load() + mre.dynamic_load()\n>>> statement = 'Total resource requirement method is not implemented correctly'\n>>> if test:\n...     score += 4\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': value}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> assert test, statement\n",
         "hidden": false,
         "locked": false,
         "points": 4,
         "success_message": "Total resource requirement implemented correctly"
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> scorer = submit_score()\n>>> question_id = 'q1_9'\n>>> max_score = 3\n>>> expected_message = 'Static Load: 2.00 GB\\nDynamic Load: 5000.00 GFLOPs\\nTotal Resource Requirement: 5002.00 (GB for static load and GFLOPs for dynamic load)'\n>>> with patch('builtins.print') as mock_print:\n...     mre = ModelResourceEstimator(model_complexity='High', data_size=10, iterations=1000, base_resource_per_iteration=5, memory_usage_static=2)\n...     mre.print_resource_requirements()\n...     mock_print.assert_called_once_with(expected_message)\n>>> if mock_print.call_args[0][0] == expected_message:\n...     score = 6\n...     drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n... else:\n...     score = 0\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': f'{mock_print.call_args[0][0]}'}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n",
         "hidden": false,
         "locked": false,
         "points": 6,
         "success_message": "Input parameters are correctly defined."
        },
        {
         "code": ">>> import drexel_jupyter_logger\n>>> from unittest.mock import patch\n>>> from ENGR131_Util_2024 import submit_score\n>>> import numpy as np\n>>> scorer = submit_score()\n>>> question_id = 'q1_9'\n>>> max_score = 5\n>>> score = 0\n>>> attributes = ['model_complexity', 'data_size', 'iterations', 'base_resource_per_iteration', 'memory_usage_static']\n>>> values = ['High', 10, 1000, 5, 2]\n>>> for (attribute, expected_value) in zip(attributes, values):\n...     actual_value = eval(f'model_resource_estimator.{attribute}')\n...     if attribute == 'model_complexity':\n...         if actual_value == expected_value:\n...             score += 1\n...     elif actual_value == expected_value:\n...         score += 1\n>>> drexel_jupyter_logger.variable_logger_csv(f'{score}, {max_score}', question_id)\n>>> response = {'question_id': question_id, 'score': score, 'max_score': max_score, 'student_response': f'Model Complexity: {model_resource_estimator.model_complexity}, \\n                                Data Size: {model_resource_estimator.data_size}, \\n                                Iterations: {model_resource_estimator.iterations}, \\n                                Base Resource per Iteration: {model_resource_estimator.base_resource_per_iteration}, \\n                                Static Memory Usage: {model_resource_estimator.memory_usage_static}\\n                                '}\n>>> scorer.add_response(response)\n>>> with patch('builtins.print') as mock_print:\n...     scorer.submit()\n>>> for (attribute, expected_value) in zip(attributes, values):\n...     assert eval(f'model_resource_estimator.{attribute}') == expected_value\n",
         "hidden": false,
         "locked": false,
         "points": 5,
         "success_message": "Input parameters are correctly defined."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}